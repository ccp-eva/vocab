---
title: "CLT Results"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggpubr)
library(tidyboot)
library(brms)
library(readxl)
library(ggthemes)
library(geomtextpath)

```

```{r}
data <- read_csv("../data/clt_clean_data.csv")

aoa <-  read_xlsx("../data/word_list.xlsx")%>%
  select(german,english, aoa_german_comb)%>%
  filter(german != "rakete")%>%
  rename(targetWord = english)%>%
  mutate(targetWord = ifelse(targetWord == "frying pan", "fryingpan", targetWord),
         targetWord = ifelse(targetWord == "courgette", "zucchini", targetWord),
         targetWord = ifelse(targetWord == "rocket", "arugula", targetWord),
         targetWord = ifelse(targetWord == "palm tree", "palmtree", targetWord))%>%
  filter(german != "kappe", 
         german != "karotte", 
         german != "mohrrÃ¼be")%>%
  distinct(german, .keep_all = T)%>%
  mutate(group = cut(aoa_german_comb, 
                   breaks=c(0, 3.5, 6, Inf), 
                   labels=c("low","middle","high")))
```

# IRT models

```{r}
irt_dat <- data%>%
  select(subjID, targetWord, correct, order, sex)
```

## 1PL model

```{r}
prior_1pl <- 
  prior("normal(0, 2)", class = "Intercept") +
  prior("normal(0, 3)", class = "sd", group = "subjID") + 
  prior("normal(0, 3)", class = "sd", group = "targetWord")
```


### Model

```{r}
irt1 <- brm(
  data = irt_dat,
  family = brmsfamily("bernoulli", "logit"),
  correct ~ 1 + (1 | targetWord) + (1 | subjID),
  prior = prior_1pl,
  control = list(adapt_delta = 0.9),
  cores = 6,
  chains = 6,
  iter = 6000
)

saveRDS(irt1, "../saves/irt1.rds")
```
### Model checks

```{r}
summary(irt1)

plot(irt1)

pp_check(irt1)
```

### ICC

```{r}
icc1 <- posterior_samples(irt1)%>% 
  select(b_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + xi + theta)) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(aoa%>%rename(item = targetWord))
```

```{r}
icc1 %>% 
  ggplot(aes(x = theta, y = p,group = item, col = aoa_german_comb)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  scale_color_viridis_c(name = "AoA") +
  labs(title = "ICCs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  theme_minimal()
```

### IIC

```{r}
iic1 <- posterior_samples(irt1)%>% 
  select(b_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + xi + theta)) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(aoa%>%rename(item = targetWord))%>%
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = median(i))%>%
  left_join(aoa%>%rename(item = targetWord))
  
```

```{r}
iic1%>%
  ggplot(aes(x = theta, y = i,group = item, col = aoa_german_comb)) +
  geom_line() +
  scale_color_viridis_c(name = "AoA") +
  labs(title = "IICs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = "Information") +
  theme_minimal()
```

### TIC
```{r}
tic1 <- posterior_samples(irt1)%>% 
  select(b_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + xi + theta)) %>% 
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, iter) %>% 
  summarise(sum_i = sum(i)) %>% 
  group_by(theta) %>% 
  summarise(i = median(sum_i))
```
```{r}
tic1%>%
  ggplot(aes(x = theta, y = i)) +
  geom_line() +
  labs(title = "TIC for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = "Information") +
  theme_minimal()
```

### Differential Item Functioning

```{r}
irt_dif_dat <- data%>%
  filter(!is.na(sex))%>%
  select(subjID,sex, targetWord, correct)


irt1_f <- brm(
  data = irt_dif_dat%>%filter(sex == "w"),
  family = brmsfamily("bernoulli", "logit"),
  correct ~ 1 + (1 | targetWord) + (1 | subjID),
  prior = c(prior(normal(0, 1.5), class = Intercept),
            prior(student_t(10, 0, 1), class = sd)),
  cores = 4,
  chains = 4,
  iter = 8000
)

irt1_m <- brm(
  data = irt_dif_dat%>%filter(sex == "m"),
  family = brmsfamily("bernoulli", "logit"),
  correct ~ 1 + (1 | targetWord) + (1 | subjID),
  prior = c(prior(normal(0, 1.5), class = Intercept),
            prior(student_t(10, 0, 1), class = sd)),
  cores = 4,
  chains = 4,
  iter = 8000
)

```

```{r}
icc1_dif <- bind_rows(
  posterior_samples(irt1_m)%>%mutate(group = "m"),
  posterior_samples(irt1_f)%>%mutate(group = "f")
)%>%
  select(b_Intercept,group, starts_with("r_targetWord"))%>%
  group_by(group)%>%
  mutate(iter = 1:n()) %>% 
  ungroup()%>%
  pivot_longer(starts_with("r_targetWord"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter,group, b_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + xi + theta)) %>% 
  group_by(theta, group,item) %>% 
  summarise(p = mean(p))
```

```{r}
icc1_dif %>% 
  ggplot(aes(x = theta, y = p,group = group, col = group)) +
  geom_line(alpha = .75) +
  facet_wrap(~item)+
  #guides(col = F)+
  scale_color_viridis_d(name = "AoA") +
  labs(title = "Group Split by sex - 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  theme_minimal()
```

## 2PL model

### Model

```{r}
prior_2pl <- 
  prior("normal(0, 2)", class = "b", nlpar = "eta") +
  prior("normal(0, 1)", class = "b", nlpar = "logalpha") +
  prior("normal(0, 1)", class = "sd", group = "subjID", nlpar = "eta") + 
  prior("normal(0, 3)", class = "sd", group = "targetWord", nlpar = "eta") +
  prior("normal(0, 1)", class = "sd", group = "targetWord", nlpar = "logalpha")
```

```{r}
irt2 <- brm(
  data = irt_dat,
  family = brmsfamily("bernoulli", "logit"),
  bf(
    correct ~ exp(logalpha) * eta,
    eta ~ 1 + (1 |i| targetWord) + (1 | subjID),
    logalpha ~ 1 + (1 |i| targetWord),
    nl = TRUE
  ),
  prior = prior_2pl,
  control = list(adapt_delta = 0.9),
  cores = 6,
  chains = 6,
  iter = 6000
)

saveRDS(irt2, "../saves/irt2.rds")
```

### Model checks

```{r}
summary(irt2)

plot(irt2)

pp_check(irt2)
```

### Easiness and discrimination

```{r}
coef_irt2 <- coef(irt2)

eta <- coef_irt2$targetWord[, , "eta_Intercept"] %>%
	as_tibble(rownames = "item")

alpha <- coef_irt2$targetWord[, , "logalpha_Intercept"] %>%
	exp() %>%
	as_tibble(rownames = "item")

params <- bind_rows(eta, alpha, .id = "nlpar") %>%
	select(-Est.Error) %>%
	mutate(nlpar = factor(nlpar, labels = c("Easiness", "Discrimination")))%>%
  left_join(aoa%>%rename(item = targetWord))

ggplot(params,aes(reorder(item, -aoa_german_comb), Estimate, ymin = Q2.5, ymax = Q97.5)) +
	facet_wrap("nlpar", scales = "free_x") +
	geom_pointrange() +
	coord_flip() +
	labs(x = "Item")+
  theme_calc()
```


### ICC

```{r}
icc2 <- posterior_samples(irt2)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(aoa%>%rename(item = targetWord))

```

```{r}
icc2 %>% 
  ggplot(aes(x = theta, y = p,group = item, col = aoa_german_comb)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  scale_color_viridis_c(name = "AoA") +
  labs(title = "ICCs for the 2PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  theme_minimal()
```

### IIC 

```{r}
iic2 <- posterior_samples(irt2)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi)))%>%
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = median(i))%>%
  left_join(aoa%>%rename(item = targetWord))
```

```{r}
iic2%>%
  ggplot(aes(x = theta, y = i,group = item, col = aoa_german_comb)) +
  geom_line() +
  scale_color_viridis_c(name = "AoA") +
  labs(title = "IICs for the 2PL",
       x = expression(theta~('ability on the logit scale')),
       y = "information") +
  theme_minimal()
```

### TIC
```{r}
tic2 <- posterior_samples(irt2)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi)))%>%
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, iter) %>% 
  summarise(sum_i = sum(i)) %>% 
  group_by(theta) %>% 
  summarise(i = median(sum_i))
```

```{r}
tic2%>%
  ggplot(aes(x = theta, y = i)) +
  geom_line() +
  labs(title = "TIC for the 2PL",
       x = expression(theta~('ability on the logit scale')),
       y = "Information") +
  theme_minimal()
```

## 3PL model


### Model

```{r}
prior_3pl_fixed <- 
  prior("normal(0, 2)", class = "b", nlpar = "eta") +
  prior("normal(0, 1)", class = "b", nlpar = "logalpha") +
  prior("normal(0, 1)", class = "sd", group = "subjID", nlpar = "eta") + 
  prior("normal(0, 3)", class = "sd", group = "targetWord", nlpar = "eta") +
  prior("normal(0, 1)", class = "sd", group = "targetWord", nlpar = "logalpha")
```


```{r}
irt3 <- brm(
  data = irt_dat,
  family = brmsfamily("bernoulli", "identity"),
  bf(
    correct ~ 0.25 + 0.75 * inv_logit(exp(logalpha) * eta),
    eta ~ 1 + (1 |i| targetWord) + (1 | subjID),
    logalpha ~ 1 + (1 |i| targetWord),
    nl = TRUE
  ),
  prior = prior_va_3pl,
  control = list(adapt_delta = 0.9),
  cores = 6,
  chains = 6,
  iter = 6000
)

saveRDS(irt3, "../saves/irt3.rds")

```

### Model checks

```{r}
summary(irt3)

plot(irt3)

pp_check(irt3)
```

### Easiness and discrimination

```{r}
coef_irt3 <- coef(irt3)

eta <- coef_irt3$targetWord[, , "eta_Intercept"] %>%
	as_tibble(rownames = "item")

alpha <- coef_irt3$targetWord[, , "logalpha_Intercept"] %>%
	exp() %>%
	as_tibble(rownames = "item")

params <- bind_rows(eta, alpha, .id = "nlpar") %>%
	select(-Est.Error) %>%
	mutate(nlpar = factor(nlpar, labels = c("Easiness", "Discrimination")))%>%
  left_join(aoa%>%rename(item = targetWord))

ggplot(params,aes(reorder(item, -aoa_german_comb), Estimate, ymin = Q2.5, ymax = Q97.5)) +
	facet_wrap("nlpar", scales = "free_x") +
	geom_pointrange() +
	coord_flip() +
	labs(x = "Item")+
  theme_minimal()
```

### ICC

```{r}
icc3 <- posterior_samples(irt3)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = 0.25 + 0.75*inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(aoa%>%rename(item = targetWord))

```

```{r}
icc3 %>% 
  ggplot(aes(x = theta, y = p,group = item, col = aoa_german_comb)) +
  geom_line() +
  #geom_textline(aes(label = item)) +
  #geom_texthline(yintercept = 0.25, lty = 3, alpha = .75, label = "guessing",hjust = 0.8)+
  geom_hline(yintercept = 0.25, lty = 3, alpha = .75)+
  #facet_wrap(~group)+
  #guides(col = F)+
  scale_color_viridis_c(name = "AoA") +
  labs(title = "ICCs for the 3PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

```{r}
icc3 %>% 
  ggplot(aes(x = theta, y = p, group = item)) +
  geom_line(data = select(icc3, -item),aes(group = german), alpha = .25, col ="grey") +
  geom_line(col = "firebrick") +
  #geom_textline(aes(label = item)) +
  #geom_texthline(yintercept = 0.25, lty = 3, alpha = .75, label = "guessing",hjust = 0.8)+
  geom_hline(yintercept = 0.25, lty = 3, alpha = .75)+
  facet_wrap(~item)+
  #guides(col = F)+
  scale_color_viridis_d(name = "AoA") +
  labs(title = "ICCs for the 3PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```


### IIC 

```{r}
iic3 <- posterior_samples(irt3)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_targetWord"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_targetWord")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi)))%>%
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = median(i))%>%
  left_join(aoa%>%rename(item = targetWord))
```

```{r}
iic3%>%
  ggplot(aes(x = theta, y = i,group = item, col = aoa_german_comb)) +
  geom_line() +
  scale_color_viridis_c(name = "AoA") +
  labs(title = "IICs for the 3PL",
       x = expression(theta~('ability on the logit scale')),
       y = "information") +
  theme_minimal()
```

## Differential Item Functioning

### Model

```{r}
irt3_dif <- brm(
  data = irt_dat,
  family = brmsfamily("bernoulli", "identity"),
  bf(
    correct ~ 0.25 + 0.75 * inv_logit(exp(logalpha) * eta),
    eta ~ 1 + (0+ sex |i| targetWord) + (1 | subjID),
    logalpha ~ 1 + (0+ sex |i| targetWord),
    nl = TRUE
  ),
  prior = prior_va_3pl,
  cores = 6,
  chains = 6,
  iter = 6000
)

saveRDS(irt3_dif, "../saves/irt3_dif.rds")
```

```{r}
coef_irt3_dif <- coef(irt3_dif)

eta <- bind_rows(
  coef_irt3_dif$targetWord[, , "eta_sexf"] %>%
	as_tibble(rownames = "item")%>%mutate(sex = "female"),
  coef_irt3_dif$targetWord[, , "eta_sexm"] %>%
	as_tibble(rownames = "item")%>%mutate(sex = "male")
  )%>%mutate(nlpar = "Easiness")

alpha <- 
  bind_rows(
    coef_irt3_dif$targetWord[, , "logalpha_sexf"] %>%
	exp() %>%
	as_tibble(rownames = "item")%>%mutate(sex = "female"),
	    coef_irt3_dif$targetWord[, , "logalpha_sexm"] %>%
	exp() %>%
	as_tibble(rownames = "item")%>%mutate(sex = "male")
  )%>%mutate(nlpar = "Discrimination")

params <- bind_rows(eta, alpha) %>%
	select(-Est.Error) %>%
  left_join(aoa%>%rename(item = targetWord))

ggplot(params,aes(reorder(item, -aoa_german_comb), Estimate, ymin = Q2.5, ymax = Q97.5)) +
	facet_wrap("nlpar", scales = "free_x") +
	geom_pointrange(aes(col = sex), position = position_dodge(width = .5)) +
	coord_flip() +
  scale_color_colorblind()+
	labs(x = "Item")+
  theme_minimal()
```


## Model comparison

```{r}
irt1 <- add_criterion(irt1, "loo") 
irt2 <- add_criterion(irt2, "loo") 
irt3 <- add_criterion(irt3, "loo") 

loo_compare(irt1, irt2, irt3)%>%as_tibble(rownames = "model")


```

```{r}
irt3_dif <- add_criterion(irt3_dif, "loo") 

loo_compare(irt3, irt3_dif)%>%as_tibble(rownames = "model")
```


# Frequentist IRT

```{r}
library(mirt)

remove <- c("telephone", "strawberry" ,"plane" ,"snake" ,"fish", "belt")

firt_dat <- irt_dat%>%
  select(-sex, -order)%>%
  filter(!targetWord %in% remove)%>%
  group_by(subjID)%>%
  distinct(targetWord, .keep_all = T)%>%
  pivot_wider(names_from = targetWord, values_from = correct)%>%
  ungroup()%>%
  select(-subjID)


firt_1F <- mirt(firt_dat, 1, itemtype = "2PL",  guess = .25,technical = list(NCYCLES = 5000))
firt_2F <- mirt(firt_dat, 2, itemtype = "2PL",  guess = .25,technical = list(NCYCLES = 5000))

anova(firt_1F, firt_2F)

firt1 <- mirt(firt_dat, 1, itemtype = "Rasch",  guess = .25)
firt2 <- mirt(firt_dat, 1, itemtype = "2PL",  guess = .25,technical = list(NCYCLES = 5000), SE = T)
firt3 <- mirt(firt_dat, 1, itemtype = "3PL",  guess = .25)

anova(firt1,firt2)
anova(firt2,firt3)

```

```{r}
coefs2PL <- coef(firt2,
     as.data.frame = TRUE,
     IRTpars = T)%>%
  as_tibble(rownames = "x")%>%
  separate(x, into = c("item", "nlpar"), sep = "\\.", remove = T)%>%
  mutate(nlpar = recode(nlpar,
                       b = "Easiness",
                       a = "Discrimination"
                      ))%>%
  filter(nlpar != "g", nlpar != "u", item != "GroupPars")
```

```{r}
traceline <- NULL
for(i in 1:43){
extr.2 <- extract.item(firt2, i)
Theta <- matrix(seq(-6,6, by = .1))
traceline[[i]] <- probtrace(extr.2, Theta)
}

# rename list
names(traceline) <- paste0('item',1:length(traceline))

# rbind traceline
traceline.df <- do.call(rbind, traceline)

# create item names length based on length of theta provided
item <- rep(names(traceline),each=length(Theta))

# put them all together into a dataframe
l.format <- cbind.data.frame(Theta, item, traceline.df)


l.format$item<-as.factor(l.format$item)
aux<-l.format %>%
  group_by(item) %>%
  slice(which.min(abs(P.1-0.5))) # We are only using the P.1 column (dichotomous)

aux<-aux[order(aux$Theta),]
ord<-as.integer(aux$item)
l.format$item = factor(l.format$item,levels(l.format$item)[ord])

names <- irt_dat%>%
  filter(!targetWord %in% remove)%>%
  distinct(targetWord, .keep_all = T)%>%
  select(targetWord)%>%
  mutate(item = paste0("item",row_number()))

format <- l.format%>%left_join(names)%>%left_join(aoa)

# plot chart
ggplot(format, aes(Theta, P.1, col = aoa_german_comb, group = item)) + 
  geom_line() + 
  #ggtitle('Probability Tracelines') + 
  xlab(expression(theta)) + 
  ylab(expression(P(theta))) + 
  #facet_wrap(~targetWord)+
  ylim(0,1)+
  scale_color_viridis_c(name = "AoA") +
  geom_hline(yintercept = 0.25, lty = 3, alpha = .75) +
  theme_bw() + 
  theme(
        axis.text.x=element_text(colour="black"),
        axis.text.y=element_text(colour="black"),
        legend.title=element_blank())
```

# Compare Bayesian and Frequentist models

```{r}
pc <- bind_rows(
format%>%
  select(-item, -P.0)%>%
  rename(item = targetWord,
         p = P.1,
         theta = Theta)%>%
  mutate(source = "frequentist"),
icc3%>%
  mutate(source = "bayesian")
)

pc %>% 
  ggplot(aes(x = theta, y = p, group = source, col = source)) +
  geom_line() +
  geom_hline(yintercept = 0.25, lty = 3, alpha = .75)+
  facet_wrap(~item)+
  #guides(col = F)+
  scale_color_colorblind() +
  labs(x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()

```
```{r}
params%>%left_join(coefs2PL)%>%
  mutate(slope = ifelse(nlpar == "Easiness", -1,1))%>%
  ggplot(aes(x = Estimate, y = par))+
  geom_abline(aes(slope = slope, intercept = 0), lty = 3, alpha = .5)+
  geom_errorbar(aes(ymin = CI_2.5, ymax = CI_97.5), alpha = .25, col = "dodgerblue")+
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5), alpha = .25, col = "dodgerblue")+
  geom_point(pch = 1, alpha = .75)+
  facet_grid(~nlpar)+
  labs(x = "Bayesian estimate", y = "Frequentist estimate")+
  stat_cor()+
  ylim(-10,10)+
  #xlim(-10,10)+
  #coord_fixed(ratio = 1)+
  scale_color_viridis_c()+
  theme_bw()
```
# Correlation subtest and full test

```{r}
select <-params %>%
  pivot_wider(names_from = nlpar, values_from = Estimate)%>%
  arrange(
    #Easiness, 
    -Discrimination
    )%>%
  slice(1:15)#%>%
  pull("item")

full <- data%>%
  group_by(subjID)%>%
  summarise(mean_full = mean(correct))

sub <- data%>%
  filter(targetWord %in% select)%>%
  group_by(subjID)%>%
  summarise(mean_sub = mean(correct))

comp <- full%>%left_join(sub)

ggplot(comp, aes(x = mean_full, y = mean_sub))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .75)+
  geom_jitter(pch = 1, alpha = .75, height = 0.01, width = 0.01)+
  stat_cor()+
  ylim(0,1.02)+
  xlim(0,1.02)+
  theme_minimal()

```

```{r}

dat <- tibble(
  iter = c(),
  items = c(),
  cor = c(),
)

full <- data%>%
  group_by(subjID)%>%
  summarise(mean_full = mean(correct))

for (i in 1:1000) {

  items <-params %>% pull("item")

  sel_items <- sample(items, 15)

  sub <- data%>%
  filter(targetWord %in% sel_items)%>%
  group_by(subjID)%>%
  summarise(mean_sub = mean(correct))

  cor <- cor(full$mean_full,sub$mean_sub)

  df <- tibble(
    iter = i,
    items = sel_items,
    cor = cor
  )
  
  dat <- bind_rows(dat,df)

}

dat%>%
  group_by(items)%>%
  summarise(mean_cor = mean(cor))%>%
  arrange(-mean_cor)
  
```



# Sources

For models

@article{burkner2019bayesian,
  title={Bayesian item response modeling in R with brms and Stan},
  author={B{\"u}rkner, Paul-Christian},
  journal={arXiv preprint arXiv:1905.09501},
  year={2019}
}

For sample size:

Morizot, J., Ainsworth, A. T., & Reise, S. P. (2007). Toward modern psychometrics: Application of item response theory models in personality research. In R. W. Robins, R. C. Fraley, & R. F. Krueger (Eds.), Handbook of Research Methods in Personality Psychology (pp. 407-423). New York: Guilford.
