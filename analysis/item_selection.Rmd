---
title: "oREV item selection"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggpubr)
library(ggthemes)
library(tidybayes)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```

```{r}
data <- read_csv("../data/clean_data.csv")

irt_dat <- data%>%
  select(subjID, targetWord, correct, order, sex, aoa_german_comb)

all_model_params <- read_csv("../data/model_parameters_3PL.csv")

params_sex <- readRDS("../saves/model_params_irt3_dif_sex.rds")%>%
  select(-uci, -lci)%>%
  pivot_wider(names_from = sex, values_from = mode)%>%
  mutate(sex_dif = f-m)

# params_order <- readRDS("../saves/model_params_irt3_dif_order.rds")%>%
#   select(-uci, -lci)%>%
#   pivot_wider(names_from = order, values_from = mode)%>%
#   mutate(order_dif = A-B)
```
# Item selection based on 3PL model

## Differential item functioning

```{r}
# exclude items based on differential item functioning
## Split by sex
params_sex_p <- params_sex%>%
  group_by(nlpar)%>%
  mutate(sd = sd(sex_dif), 
         cut_low = mean(sex_dif)-2*sd,
         cut_high = mean(sex_dif)+2*sd)


ggplot(params_sex_p, aes(x = sex_dif))+
  geom_vline(aes(xintercept = cut_low), lty = 3, alpha = .75)+
  geom_vline(aes(xintercept = cut_high), lty = 3, alpha = .75)+
  geom_histogram(col = "black", alpha = .5)+
  facet_grid(~nlpar)+
  theme_minimal()

ggplot(params_sex_p, aes(x = sex_dif, label = item, y = reorder(item, abs(sex_dif))))+
  geom_vline(aes(xintercept = cut_low), lty = 3, alpha = .75)+
  geom_vline(aes(xintercept = cut_high), lty = 3, alpha = .75)+
  geom_point(col = "black", alpha = .5)+
  facet_grid(~nlpar)+
  theme_minimal()

exclude_sex <- params_sex_p%>%
  filter(sex_dif < cut_low | sex_dif > cut_high)%>%
  pull(item)

## Split by Order
### not necessary since model comparison says order adds no predictive value

# params_order_p <- params_order%>%
#   group_by(nlpar)%>%
#   mutate(sd = sd(order_dif), 
#          cut_low = mean(order_dif)-2*sd,
#          cut_high = mean(order_dif)+2*sd)
# 
# ggplot(params_order_p, aes(x = order_dif))+
#   geom_vline(aes(xintercept = cut_low), lty = 3, alpha = .75)+
#   geom_vline(aes(xintercept = cut_high), lty = 3, alpha = .75)+
#   geom_histogram(col = "black", alpha = .5)+
#   facet_grid(~nlpar)+
#   theme_minimal()
# 
# 
# ggplot(params_order_p, aes(x = order_dif, label = item, y = reorder(item, abs(order_dif))))+
#   geom_vline(aes(xintercept = cut_low), lty = 3, alpha = .75)+
#   geom_vline(aes(xintercept = cut_high), lty = 3, alpha = .75)+
#   geom_point(col = "black", alpha = .5)+
#   facet_grid(~nlpar)+
#   theme_minimal()
# 
# exclude_order <- params_order_p%>%
#   filter(order_dif < cut_low | order_dif > cut_high)%>%
#   pull(item)
# 
# 
model_params <- all_model_params%>%
  filter(!item %in% exclude_sex)
```

```{r}
items <- model_params%>%filter(nlpar=="Easiness")%>%pull(item)
easiness <- filter(model_params, nlpar=="Easiness") %>% pull(Estimate)
easy_spread <- model_params%>%filter(nlpar=="Easiness")%>%mutate(width = abs(Q97.5 - Q2.5)) %>% pull(width)
discrimination <- filter(model_params, nlpar=="Discrimination") %>% pull(Estimate)

full <- data%>%
  group_by(subjID)%>%
  summarise(mean_full = mean(correct))
```


```{r}
easb <- tibble()

for (j in 1:100) {
  
for (i in 1:48) {
  
  x <- sample(easiness, i)
  
	nn_dists <- rep(0, length(x)-1)
	for(k in 1:length(x)-1) {
		nn_dists[k] <- x[k+1] - x[k]
	}
	
	spacing <- -1*sd(nn_dists)

	row <- tibble(iter = j,
                size = i, 
                mean = spacing/2)
  easb <- bind_rows(easb,row)
}
}

ggplot(easb, aes(x = factor(size), y = mean))+
  geom_point(pch = 1)+
  theme_minimal()

```


```{r}
discrimb <- tibble()

for (j in 1:100) {
  
for (i in 1:48) {
  x <- sample(discrimination, i)
  mean_x <- mean(x)
  row <- tibble(iter = j,
                size = i, 
                mean = mean_x/2)
  discrimb <- bind_rows(discrimb,row)
}
}

ggplot(discrimb, aes(x = factor(size), y = mean))+
  geom_point(pch = 1)+
  theme_minimal()

```

```{r}
spreadb <- tibble()

for (j in 1:100) {
  
for (i in 1:48) {
  x <- sample(easy_spread, i)
  mean_x <- mean(x)
  row <- tibble(iter = j,
                size = i, 
                mean = mean_x/5)
  spreadb <- bind_rows(spreadb,row)
}
}
  
ggplot(spreadb, aes(x = factor(size), y = mean))+
  geom_point(pch = 1)+
  theme_minimal()

```



```{r}
score_fn <- function(subset) {
	easinesses <- sort(easiness[subset])
	nn_dists <- rep(0, sum(subset)-1)
	for(i in 1:sum(subset)-1) {
		nn_dists[i] <- easinesses[i+1] - easinesses[i]
	}
	spacing <- -1*sd(nn_dists)
	mean_discrim <- mean(discrimination[subset])
	mean_spread <- mean(easy_spread[subset])
	 
	# sel <- items[subset == TRUE]
	# 
	# sub_dat <- data%>%
	#   filter(targetWord %in% sel)%>%
	#   group_by(subjID)%>%
	#   summarise(mean_sub = mean(correct))
	# 
	# cor <- cor(sub_dat$mean_sub,full$mean_full)
	# 
	# return(spacing + mean_discrim/6 + cor/3)
	return(spacing + mean_discrim/2 - mean_spread/5)
}


proposal_fn <- function(subset) {
	# Randomly sample a number of swaps.
	# Prefer a small number of swaps for "fine tuning", but allow
	# occasional large numbers of swaps, including a complete
	# exchange of the subset
	subset_size = sum(as.integer(subset))
	max_swaps = min(subset_size, length(subset) - subset_size)
	swaps <- rbinom(1, max_swaps-1, 1/(max_swaps-1)) + 1

	# Choose the items to swap
	active_items <- seq(1:length(subset))[subset == TRUE]
	inactive_items <- seq(1:length(subset))[subset == FALSE]
	actives_to_swap <- sample(active_items, swaps)
	inactives_to_swap <- sample(inactive_items, swaps)

	# Do the swapping
	for(i in 1:swaps) {
		subset[actives_to_swap[i]] <- FALSE
		subset[inactives_to_swap[i]] <- TRUE
	}
	return(subset)
}

simulated_annealing <- function(k, cooling_ratio=0.999, reset_thresh=1000, break_thresh=10000) {
  easiness <- filter(model_params, nlpar=="Easiness") %>% pull(Estimate)
  easy_spread <- model_params%>%filter(nlpar=="Easiness")%>%mutate(width = abs(Q97.5 - Q2.5)) %>% pull(width)
  discrimination <- filter(model_params, nlpar=="Discrimination") %>% pull(Estimate)
	N <- length(easiness)

	current_subset <- sample(c(rep(TRUE, k), rep(FALSE, N-k)))
	best_subset <- current_subset
	best_score <- score_fn(best_subset)

	temp <- 100
	rejected <- 0
	no_new_bests <- 0
	for(i in 1:1e6) {
		# Score new subset, and toss a coin
		new_subset <- proposal_fn(current_subset)
		new_score <- score_fn(new_subset)
		accept_decrease <- rbernoulli(1, temp / 100)

		# Accept the new subset if it's an improvement, or if our
		# cooling coin came up heads.
		if(new_score > best_score | accept_decrease) {
			current_subset <- new_subset
			rejected <- 0
			if(new_score > best_score) {
				best_subset <- new_subset
				best_score <- new_score
				no_new_bests <- 0
			} else {
				no_new_bests <- no_new_bests + 1
			}
		# Quit if we've had too many rejections in a row.
		} else {
			rejected <- rejected + 1
			no_new_bests <- no_new_bests + 1
			if(rejected == break_thresh) {
				#print(best_score)
			  ret <- tibble(best_subset = list(best_subset),
	              best_score = best_score)
			  
				return(ret)
			}
		}
		# Start random resets to the current best subset if we haven't
		# found anything better in quite a while.
		if(no_new_bests > reset_thresh & rbernoulli(1, 1/100)) {
			current_subset <- best_subset
		}

		# Cool it!
		temp <- temp*cooling_ratio
	}
	#print(best_score)
	ret <- tibble(best_subset = list(best_subset),
	              best_score = best_score)
	
	return(ret)
}
```

```{r, message=F, warning=F, comment=F}
sim_a <- simulated_annealing(20)

sel_items <- items[unlist(sim_a$best_subset) == TRUE]

sim_a$best_score
```


## Visualize parameters of selected items

```{r}
model_params%>%
  filter(item %in% sel_items)%>%
  ggplot(aes(reorder(item, -Estimate), Estimate, ymin = Q2.5, ymax = Q97.5)) +
	facet_wrap(~nlpar, scales = "free_x") +
	geom_pointrange() +
	coord_flip() +
	labs(x = "Item")+
  theme_minimal()
```

## Correaltion with full test

```{r}
sub2 <- data%>%
  filter(targetWord %in% sel_items)%>%
  group_by(age_group,subjID)%>%
  summarise(mean_sub = mean(correct))

comp2<- full%>%left_join(sub2)

ggplot(comp2, aes(x = mean_full, y = mean_sub))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .75)+
  geom_jitter(pch = 1, alpha = .75, height = 0.01, width = 0.01)+
  stat_cor()+
  facet_wrap(~age_group)+
  ylim(0,1.02)+
  xlim(0,1.02)+
  theme_few()
```

## Variation in score 

```{r, warning=FALSE}
sim_score <- tibble()

for (i in 5:35) {
  
  for (j in 1:10) {
  
   sim <- simulated_annealing(i)
  
   score <- tibble(score = sim$best_score, 
                   size = i,
                   iter = j)
   
   sim_score <- bind_rows(sim_score, score)
  }
  
}

sim_score%>%
  ggplot(aes(x = size, y = score, group = iter))+
  geom_point(pch = 1)+
  theme_minimal()
```

## Determine size

```{r, warning=FALSE}
sim_size <- tibble()

for (j in 1:100) {
  
for (i in 5:40) {
  
   sim <- simulated_annealing(i)
  
    sel <- items[unlist(sim$best_subset) == TRUE]


	sub_dat <- data%>%
	  filter(targetWord %in% sel)%>%
	  group_by(subjID)%>%
	  summarise(mean_sub = mean(correct))

	cor <- cor(sub_dat$mean_sub,full$mean_full)
	
	row <- tibble(size = i, 
         iter = j, 
         cor = cor)
  
  sim_size <- bind_rows(sim_size, row)
}

}
  
saveRDS(sim_size, "../saves/sim_size.rds")

sim_size%>%
  group_by(size)%>%
  summarise(mean_cor = mean(cor),
         min = min(cor),
         max = max(cor))%>%
  ggplot(aes(x = factor(size), y = mean_cor))+
  geom_pointrange(aes(ymin=min, max = max), pch = 1)+
  geom_line(aes(group = 1))+
  scale_linetype(name = "Run")+
  theme_minimal()+
  labs(x = "No. of items", y = "Correlation with full test")

```

```{r, warning=FALSE}
sim_size_age <- tibble()

for (j in 1:100) {
  
for (i in 5:40) {
  
   sim <- simulated_annealing(i)
  
    sel <- items[unlist(sim$best_subset) == TRUE]
  
    cor <- data%>%
      filter(targetWord %in% sel)%>%
      group_by(age_group,subjID)%>%
  summarise(mean_sub = mean(correct))%>%
  right_join(full)%>%
  group_by(age_group)%>%
  summarise(cor = cor(mean_sub, mean_full))%>%
  mutate(size = i, 
         iter = j)
  
  sim_size_age <- bind_rows(sim_size_age, cor)
}

}

saveRDS(sim_size_age, "../saves/sim_size_age.rds")

sim_size_age%>%
  group_by(size, age_group)%>%
  summarise(mean_cor = mean(cor),
         min = min(cor),
         max = max(cor))%>%
  ggplot(aes(x = factor(size), y = mean_cor, col = factor(age_group)))+
  geom_pointrange(aes(ymin=min, max = max), pch = 1)+
  geom_line(aes(group = factor(age_group)))+
  theme_minimal()+
  scale_linetype(name = "Run")+
  #facet_grid(factor(iter)~.)+
  labs(x = "No. of items", y = "Correlation with full test")+
  scale_color_colorblind(name = "Age group")

```

## Select items

```{r}
item_sel <- tibble()

for (i in 1:100) {
  
   sim <- simulated_annealing(20)
  
   sel <- items[unlist(sim$best_subset) == TRUE]
  
   it <- data%>%
     distinct(targetWord)%>%
     filter(targetWord %in% sel)%>%
     select(targetWord)%>%
     mutate(iter = i)
   
   item_sel <- bind_rows(item_sel, it)
}

item_sel%>%
  group_by(targetWord)%>%
  summarise(n = n()/max(iter))%>%
  ggplot(aes(x = reorder(targetWord, -n), y = n))+
  geom_bar(stat = "identity", col = "black", fill = "white")+
  labs(x = "Item", y = "Proportion selected")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## ICC for subset

```{r}
frq_sel_items <- item_sel%>%
  group_by(targetWord)%>%
  summarise(n = n()/max(iter))%>%
  arrange(-n)%>%
  slice(1:20)%>%
  pull(targetWord)

saveRDS(frq_sel_items, "../saves/selected_items.rds")


icc3 %>% 
  filter(item %in% frq_sel_items)%>%
  #mutate(sel = ifelse(item %in% frq_sel_items, "a", "b"))%>%
  #filter(item == "orchid")%>%
  ggplot(aes(x = theta, y = p,group = item, col = aoa_german_comb)) +
  #geom_line(alpha = .5) +
  #geom_line(col = "firebrick", alpha = .5) +
  geom_textline(aes(label = item)) +
  #geom_texthline(yintercept = 0.25, lty = 3, alpha = .75, label = "guessing",hjust = 0.8)+
  geom_hline(yintercept = 0.25, lty = 3, alpha = .75)+
  #facet_wrap(~group)+
  guides(col = F)+
  scale_color_viridis_c(name = "AoA") +
  #scale_color_manual(values = c("firebrick", "grey"))+
  labs(#title = "ICCs for selected items",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```
## Correaltion selected with full test

```{r}
subsel <- data%>%
  filter(targetWord %in% frq_sel_items)%>%
  group_by(age_group,subjID)%>%
  summarise(mean_sub = mean(correct))

compsel<- full%>%left_join(subsel)

ggplot(compsel, aes(x = mean_full, y = mean_sub))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .75)+
  geom_jitter(pch = 1, alpha = .75, height = 0.01, width = 0.01)+
  stat_cor()+
  #facet_wrap(~age_group)+
  labs(#title = "ICCs for selected items",
       x = "Full test - proportion correct",
       y = "Short test - proportion correct") +
  ylim(0,1.02)+
  xlim(0,1.02)+
  theme_few()
```


```{r}
model_params%>%
  filter(item %in% frq_sel_items)%>%
  ggplot(aes(reorder(item, -Estimate), Estimate, ymin = Q2.5, ymax = Q97.5)) +
	facet_wrap(~nlpar, scales = "free_x") +
	geom_pointrange() +
	coord_flip() +
	labs(x = "Item")+
  theme_minimal()
```

# Item selection based on Rasch Model 

```{r}
irt1 <- readRDS("../saves/irt1.rds")

rasch_fit <- irt_dat%>%
  select(-order, -sex)%>%
  filter(#targetWord %in% c("door", "jaguar","zucchini"),
         #subjID %in% c("15X7mwV1", "39tVizn3", "479FefBH")
         )%>%
  add_epred_draws(irt1, re_formula = ~(1 | targetWord) + (1 | subjID), ndraws = 5000)%>%
  mutate(zvi = (correct - .epred)/(.epred*(1-.epred))^0.5)%>%
  group_by(targetWord,aoa_german_comb, .draw)%>%
  summarise(outfit = sum(zvi^2)/length(unique(subjID)),
            infit = (sum(zvi^2*(.epred*(1-.epred)))/sum(.epred*(1-.epred))))



rasch_fit_mode <- rasch_fit%>%
  pivot_longer(names_to = "fit_index", values_to = "value", cols = c(outfit, infit))%>%
  group_by(targetWord, fit_index)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))
  

rasch_sel_items <- rasch_fit_mode%>%
  select(-lci, -uci)%>%
  pivot_wider(names_from = fit_index, values_from = mode)%>%
  filter(0.5 < infit & 1.5 > infit,
         0.5 < outfit & 1.5 > outfit)%>%
  pull(targetWord)


saveRDS(rasch_sel_items, "../saves/rasch_selected_items.rds")
```

```{r}
rasch_fit%>%
  pivot_longer(names_to = "fit_index", values_to = "value", cols = c(outfit, infit))%>%
  ggplot(. , aes(y = fct_reorder(targetWord, aoa_german_comb), x = value, fill = fit_index, col = fit_index))+
  geom_vline(xintercept = c(0.7, 1.3), lty = 3, alpha = .5)+
  geom_vline(xintercept = 1, lty = 1, alpha = .5, col = "darkgreen")+
  stat_halfeye(alpha = .75, .width = c(0.66, 0.95))+
  scale_fill_colorblind()+
  scale_color_colorblind()+
  #facet_grid(~fit_index)+
  xlim(0,10)+
  theme_bw()
```

